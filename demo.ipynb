{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Notebook_Anomaly_Detection.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoTzGiPBRHkL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Novelty Detection with Autoencoders for System Health Monitoring in Industrial Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: you can run **[this notebook live in Google Colab](https://colab.research.google.com/github/softlab-unimore/SBDIOI40/blob/master/demo.ipynb)** and use free GPUs provided by Google.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhcqpnSHRqZy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Predictive Maintenance (PdM) is the newest strategy for maintenance management in industrial contexts.\n",
    "It aims to predict the occurrence of a failure to minimize unexpected downtimes and maximize the useful life of components.\n",
    "In data-driven approaches, PdM makes use of Machine Learning (ML) algorithms to extract relevant features from signals,\n",
    "identify and classify possible faults (diagnostics), and predict the components’ remaining useful life (prognostics).\n",
    "The major challenge lies in the high complexity of industrial plants, where both operational conditions change over time\n",
    "and a large number of unknown modes occur. A solution to this problem is offered by novelty detection,\n",
    "where a representation of the machinery normal operating state is learned and compared with online measurements\n",
    "to identify new operating conditions. In this paper, a systematic study of autoencoder-based methods for novelty\n",
    "detection is conducted. We introduce an architecture template, which includes a classification layer\n",
    "to detect and separate the operative conditions, and a localizer for identifying the most influencing signals.\n",
    "Four implementations, with different deep learning models, are described and used to evaluate the approach"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8gXwU0FL8QoV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fb289249-a7f6-433c-cc9e-41f4966c1012",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!git clone https://github.com/softlab-unimore/AE4ND\n",
    "!pip install -q -r AE4ND/requirements.txt"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'SBDIOI40'...\n",
      "remote: Enumerating objects: 454, done.\u001B[K\n",
      "remote: Counting objects: 100% (454/454), done.\u001B[K\n",
      "remote: Compressing objects: 100% (188/188), done.\u001B[K\n",
      "remote: Total 454 (delta 258), reused 450 (delta 257), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (454/454), 5.57 MiB | 15.04 MiB/s, done.\n",
      "Resolving deltas: 100% (258/258), done.\n",
      "\u001B[K     |████████████████████████████████| 153kB 13.5MB/s \n",
      "\u001B[?25h"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uF1HbEEgClpp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('./AE4ND')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0UrICyKoxlAO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, adjusted_mutual_info_score\n",
    "\n",
    "from ae4nd.utils.tools import prepare_data\n",
    "from ae4nd.transformations.transformer import fit_and_transform_data_list, transform_data_list\n",
    "from ae4nd.models.autoencoder import AutoEncoder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "window = 200  # Windows size to sample the multivariate time series during the sliding window process\n",
    "stride = 1  # How far the window should move at each step,\n",
    "transform_type = 'minmax'  # Type of transformation to apply to all the selected time series\n",
    "model_type = 'fcnn'  # Autoencoder models: cnn, fcnn, lstm, bilstm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of files used to train the autoencoder to learn normal behaviors\n",
    "train_files = [('data/series_state_1_1.csv', 1), ('data/series_state_2_1.csv', 2), ]\n",
    "\n",
    "# List of files used to test the trained autoencoder to be able to detect normal and novel behaviors\n",
    "test_files = [('data/series_state_1_2.csv', 1), ('data/series_state_2_2.csv', 2),\n",
    "              ('data/series_state_3_1.csv', 3), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read train and test files\n",
    "df_train_list = [pd.read_csv(file) for file, _ in train_files]\n",
    "y_train_list = [label for _, label in train_files]\n",
    "df_test_list = [pd.read_csv(file) for file, _ in test_files]\n",
    "y_test_list = [label for _, label in test_files]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply the selected transformation\n",
    "x_train_list, transformer = fit_and_transform_data_list(df_train_list, transform_type)\n",
    "x_test_list = transform_data_list(df_test_list, transformer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create train and test matrix set\n",
    "x_train, y_train = prepare_data(x_train_list, labels=y_train_list, window=window, stride=stride)\n",
    "x_test, y_test = prepare_data(x_test_list, labels=y_test_list, window=window, stride=stride)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Randomize training data\n",
    "order = np.random.permutation(len(x_train))\n",
    "x_train = x_train[order]\n",
    "y_train = y_train[order]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AutoEncoder unsupervised novelty detection\n",
    "model = AutoEncoder(model_type=model_type)  # define the autoencoder\n",
    "model.fit(x_train, epochs=10, batch_size=32, verbose=0)  # train the autoencoder\n",
    "\n",
    "# Predict novel and normal states for each sample\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute labels for novelty detection task\n",
    "print('\\nNovelty detection accuracy')\n",
    "y_true = [1 if label not in y_train_list else 0 for label in y_test]\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Classify record detected like normal state\n",
    "x_test2 = x_test[y_pred == 0]\n",
    "y_test2 = y_test[y_pred == 0]\n",
    "# Autoencoder unsupervised classification\n",
    "y_pred2 = model.classify(x_test2, supervised=False, n_clusters=2)\n",
    "print('\\nUnsupervised classification accuracy')\n",
    "print('AMI', adjusted_mutual_info_score(y_test2, y_pred2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}